#!/bin/bash

# This script outlines a comprehensive bioinformatics pipeline designed to preprocess, analyze, and interpret high-throughput sequencing data. 
# The process begins with merging and trimming FASTQ files to remove adapters and clean up the sequence data, ensuring quality inputs for alignment. 
# Trimming is performed using Porechop, followed by Quality Control assessments with NanoPlot to verify data integrity and readiness for downstream analysis. 
# The next step involves aligning the cleaned reads to a reference genome using BWA, producing BAM files that map the reads appropriately within genomic coordinates.
# These BAM files are then sorted, and duplicates are marked to reduce biases incidental to PCR amplification, using tools such as Samtools. 
# Finally, featureCounts is used to quantify gene expression levels by measuring how many reads align to each genomic feature, such as a gene or exon, 
# providing key data for differential expression studies and other genomic investigations. 
# This pipeline integrates essential preprocessing steps to ensure that the data is of high quality and ready for comprehensive genomic analyses.




module load porechop/0.2.4
module load nanoplot/1.43.0
module load bwa/0.7.17
module load samtools/1.20
module load subread/2.0.2

# Identify folder paths and reference path
FOLDER="/srv/scratch/z3546698/true/Small_Molecule/JQ1/T7MB-2/231104"  # Main directory path
REFERENCE="/srv/scratch/z3546698/true/reference/hg38.fa"
ANNOTATION="/srv/scratch/z3546698/true/reference/Homo_sapiens.GRCh38.110.gtf"


# Step 1: Trimming fastq files using Porechop
# This step merges all FASTQ files within each subdirectory, then uses Porechop to trim adapters and other unwanted sequences. This prepares high-quality data for alignment by cleaning up the reads.

echo "Trimming starts using Porechop......"

# Find directories like R0, R1, etc., and process each independently
find "$FOLDER" -type d -name "R*" | while IFS= read -r dir; do
    echo "Processing directory: $dir"
    
    # Define the output merged file path within the current directory
    merged_file="$dir/all_sequences.fastq.gz"
    
    # Initialize or clear the existing merged file
    > "$merged_file"

    # Find and merge all fastq files in the current directory
    find "$dir" -type f \( -name "*.fastq" -o -name "*.fastq.gz" \) -print0 | while IFS= read -r -d '' file; do
        echo "Merging file: $file"
        if [[ "$file" == *.gz ]]; then
            zcat "$file" >> "$merged_file"
        else
            cat "$file" >> "$merged_file"
        fi
    done

    # Check if the merging was successful
    if [ -s "$merged_file" ]; then
        echo "Files have been successfully merged into $merged_file. Deleting original files..."
        # Remove the original files in the current directory, excluding the merged file
        find "$dir" -type f \( -name "*.fastq" -o -name "*.fastq.gz" \) ! -name "all_sequences.fastq.gz" -delete
    else
        echo "Merging failed for directory $dir, original files have not been deleted."
    fi

    # Create step1 directory for Porechop output
    step1_dir="$dir/step1"
    mkdir -p "$step1_dir"
    output_file="$step1_dir/all_trimmed.fastq.gz"
    log_file="$step1_dir/porechop.log"
    
    # Run Porechop and redirect logs
    porechop -i "$merged_file" -o "$output_file" > "$log_file" 2>&1
    echo "Trimmed: $merged_file -> $output_file"
    echo "Log saved to: $log_file"
done



# Step 2: Quality Control via NanoPlot
# This step performs a quality control check using NanoPlot on the trimmed FASTQ files, providing detailed statistical and visual analyses of read quality that inform any subsequent data processing or filtering decisions.

echo "Trimming finished......."
echo "Quality Control in progress......."
find "$FOLDER" -type f -path "*/step1/*_trimmed.fastq.gz" | while read -r trimmed_file; do
    quality_control_dir="$(dirname "$trimmed_file")/../quality_control"
    mkdir -p "$quality_control_dir"
    NanoPlot --fastq "$trimmed_file" --outdir "$quality_control_dir/$(basename "${trimmed_file%.fastq.gz}_nanop")"
done

echo "Quality Control finished........"

# Step 3: Alignment and BAM file generation
# The goal here is to align trimmed reads to a reference genome using BWA, converting them into BAM files. This positions each read along the genome, allowing for further analyses like variant calling or expression quantification.

echo "Alignment and BAM file generation in progress......."
find "$FOLDER" -type f -path "*/step1/*_trimmed.fastq.gz" | while read -r trimmed_file; do
    dir=$(dirname "$trimmed_file")
    step1_dir="${dir}/../step1"
    mkdir -p "$step1_dir"
    basename=$(basename "$trimmed_file" .fastq.gz)
    output_bam="$step1_dir/${basename}.bam"
    bwa mem "$REFERENCE" "$trimmed_file" | samtools view -Sb - > "$output_bam"
    echo "BAM file generated in step1 directory: $output_bam"
done

# Step 4: Sort and mark duplicates in BAM files
# This step involves sorting the aligned BAM files and marking duplicate reads. Sorting organizes reads for efficient access and processing, while marking duplicates helps reduce biases in downstream analyses by indicating which reads are likely artifacts of PCR amplification.

echo "Sorting and marking duplicates......."
find "$FOLDER" -type f -path "*/step1/*.bam" | while read -r bam_file; do
    dir=$(dirname "$bam_file")
    basename=$(basename "$bam_file" .bam)
    step2_dir="${dir}/../step2"
    mkdir -p "$step2_dir"
    sorted_bam="${step2_dir}/${basename}_sorted.bam"
    marked_bam="${step2_dir}/${basename}_marked.bam"
    metrics_file="${step2_dir}/${basename}_metrics.txt"

    samtools sort -o "$sorted_bam" "$bam_file"
    echo "Sorted BAM file: $sorted_bam"

    # Use samtools markdup
    samtools markdup "$sorted_bam" "$marked_bam"
    echo "Marked duplicates in BAM file: $marked_bam"

    # Optional cleanup if using Picard
    # rm "$sorted_bam"
done

echo "Sorting and marking duplicates finished......."

# Step 5: Feature Counting
# This final processing step uses featureCounts to quantify gene expression by counting aligned reads at specific genomic features, such as genes or exons. This data is essential for downstream analyses like differential expression studies, allowing researchers to compare gene activity levels across different samples or conditions.

echo "Feature counting with featureCounts......."
find "$FOLDER" -mindepth 1 -maxdepth 1 -type d | while read -r r_folder; do
    r_group=$(basename "$r_folder")
    step2_dir="${r_folder}/step2"
    step3_dir="${r_folder}/step3"
    mkdir -p "$step3_dir"
    mapfile -t bam_files < <(find "$step2_dir" -type f -name "*.bam")

    if [ ${#bam_files[@]} -eq 0 ]; then
        echo "No BAM files found in $step2_dir, skipping."
        continue
    fi

    output_counts="${step3_dir}/${r_group}_combined_expression_counts.txt"
    featureCounts -a "$ANNOTATION" -o "$output_counts" -T 4 "${bam_files[@]}"
    echo "Combined feature counts for $r_group are in: $output_counts"
done

echo "All preprocessing done. Please check the sequencing quality and expression counts reports!"
