#!/bin/bash

# Overview of the Bioinformatics Data Processing Pipeline

#This script is designed to process high-throughput sequencing data by executing a series of automated data processing steps on specified folders containing FASTQ files. The main functionalities include:
#1. **Merging and Trimming FASTQ Files**: It merges all FASTQ files within each sample directory into a single file and trims the merged file using Porechop to remove low-quality sequences and adapter sequences.
#2. **Quality Control**: Utilizes NanoPlot to assess the quality of the trimmed sequences, ensuring the reliability of the data.
#3. **Alignment and Coverage Analysis**: Leverages Minimap2 to align the trimmed sequences to a reference genome, generating BAM files and calculating read coverage, which is then output to `coverage.txt`.
#4. **Position Extraction and BED File Generation**: Extracts relevant gene positions from the coverage data and generates a BED file for easier visualization and downstream analysis.
#5. **Sequence Extraction**: Based on the generated BED file, extracts specified regions from the reference sequences and saves them in FASTA format for further analysis and applications.

#This script provides an automated workflow for bioinformatics research, significantly increasing data processing efficiency while ensuring accuracy and consistency in the results.


# What you what to modify:
# 1.Change the line 31 FASTQ_FOLDER to your/fastq/path
# 2.Change the line 36 REFERENCE to your/reference/path

module load porechop/0.2.4
module load nanoplot/1.43.0
module load samtools/1.20
module load seqkit/2.5.1 
module load minimap2/2.26

# Define paths
FASTQ_FOLDER=(
    "/mnt/d/Bait_Glue/CRBN/glue/TON/240427"
    "/mnt/d/Bait_Glue/CRBN/MB014/TON/230827"
)

REFERENCE="/mnt/d/Bait_Glue/TargetLibrary_cDNA.fasta"

# Define the pattern to match and replace
PATTERN="^((?:.*?\n){3}).*?(GATCCGAATTC[ACGTN].*$)(\n.*)"

for folder in "${FASTQ_FOLDER[@]}"; do
    # Iterate over directories like R0, R1, etc.
    find "$folder" -mindepth 1 -maxdepth 1 -type d -name "R*" | while IFS= read -r sample_dir; do
        echo "Processing directory: $sample_dir"
        
        # Define paths for step1 and step2
        step1_dir="${sample_dir}/step1"
        step2_dir="${sample_dir}/step2"
        
        # Create directories if they don't exist
        mkdir -p "$step1_dir"
        mkdir -p "$step2_dir"
        
        # Merge FASTQ files
        merged_file="${step1_dir}/all_sequences.fastq.gz"
        find "$sample_dir" -type f -name "*.fastq.gz" -print0 | xargs -0 cat > "$merged_file"

        # Check if the merge was successful
        if [ -s "$merged_file" ]; then
            echo "Files successfully merged into $merged_file."

            # Pre-process sequences with seqkit
            seqprocessed_file="${step1_dir}/all_sequences_processed.fastq.gz"
            seqkit replace -p "$PATTERN" -r '$1$2$3' -o "$seqprocessed_file" "$merged_file"
            echo "Sequences processed by seqkit and output to $seqprocessed_file."

            # Perform trimming
            trimmed_file="${step1_dir}/all_trimmed.fastq.gz"
            log_file="$step1_dir/porechop.log"
            porechop -i "$seqprocessed_file" -o "$trimmed_file" -t 24 > "$log_file" 2>&1
            
            # Remove the original FASTQ files after processing, excluding files starting with 'all'
            find "$sample_dir" -type f -name "*.fastq.gz" ! -name "all*.fastq.gz" -delete
            echo "Original FASTQ files deleted from directory: $sample_dir (excluding 'all' prefixed files)"
        
            # Quality control using NanoPlot
            quality_control_dir="${sample_dir}/quality_control"
            mkdir -p "$quality_control_dir"
            NanoPlot --fastq "$trimmed_file" --outdir "${quality_control_dir}/"
        
            # Align reads to the reference genome with Minimap2 and create BAM file
            bam_file="${step2_dir}/aligned.bam"
            minimap2 -ax map-ont "$REFERENCE" "$trimmed_file" | samtools view -Sb - > "$bam_file"

            # Sort BAM file
            sorted_bam_file="${step2_dir}/aligned_sorted.bam"
            samtools sort -o "$sorted_bam_file" "$bam_file"
        
            # Calculate coverage
            coverage_file="${step2_dir}/coverage.txt"
            samtools depth "$sorted_bam_file" > "$coverage_file"
            
            echo "Finished processing directory: $sample_dir. Results saved in step1 and step2."
        else
            echo "Merging failed for directory: $sample_dir. Skipping processing."
        fi
    done

    # Handle extraction for each processed directory
    find "$folder" -mindepth 1 -maxdepth 1 -type d -name "R*" | while IFS= read -r sample_dir; do
        echo "Processing directory for extraction: $sample_dir"
        
        step2_dir="${sample_dir}/step2"
        
        # Paths for necessary files
        coverage_file="${step2_dir}/coverage.txt"
        output_bed="${step2_dir}/positions.bed"

        # Check if the coverage file exists before proceeding
        if [ -f "$coverage_file" ]; then
            
            echo "Preparing positions in new range format..."

            # Prepare ranges from coverage and generate positions.txt with coverage values
            awk '{
                key = $1;  # Gene name
                position = $2;  # Start position
                coverage = $3;  # Coverage value

                # Store the start and end positions in an array
                if (key in positions) {
                    if (position < positions[key][1]) {
                        positions[key][1] = position;  # Update minimum start
                    }
                    positions[key][2] = position;      # Update to current position (end)
                    positions[key][3] += coverage;     # Accumulate coverage
                } else {
                    positions[key][1] = position;  # Initialize min start
                    positions[key][2] = position;  # Initialize min end
                    positions[key][3] = coverage;  # Initialize coverage
                }
            } END {
                for (gene in positions) {
                    # Print the gene with start-end range and total coverage
                    print gene "\t" positions[gene][1] "\t" positions[gene][2] "\t" positions[gene][3];
                }
            }' "$coverage_file" > "${step2_dir}/positions.txt"

            # Sort to get the top 100 genes by coverage
            sort -k4,4nr "${step2_dir}/positions.txt" | head -n 100 > "${step2_dir}/top_100_positions.txt"

            # Now create BED files from the top 100 genes
            visualization_dir="${step2_dir}/visualization"
            mkdir -p "$visualization_dir"  # Ensure visualization directory exists

            # Initialize a counter
            counter=0
            max_bed_files=100

            while IFS=$'\t' read -r gene_id start end total_coverage; do
                # Check if we've reached the maximum number of BED files
                if [ "$counter" -ge "$max_bed_files" ]; then
                    echo "Reached maximum of $max_bed_files BED files. Stopping."
                    break
                fi

                # Generate the individual BED file name
                bed_file="${visualization_dir}/${gene_id}.bed"

                # Write the gene position to the new BED file
                echo -e "$gene_id\t$start\t$end" > "$bed_file"
                echo "Created BED file for $gene_id at $bed_file"

                # Increment the counter
                counter=$((counter + 1))
            done < "${step2_dir}/top_100_positions.txt"

            # Step 2: Initialize the output FASTA file
            > "$output_fasta"  # Clear the output file
        else
            echo "Necessary coverage file not found in $step2_dir. Skipping directory."
        fi
    done
done

echo "All directories processed."

